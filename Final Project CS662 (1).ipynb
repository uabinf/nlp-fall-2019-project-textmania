{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter, ExcelFile\n",
    "\n",
    "#Numpy\n",
    "import numpy as np\n",
    "\n",
    "#NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop = stopwords.words('english')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "#SkLearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Other\n",
    "import string\n",
    "import seaborn as sns\n",
    "import yellowbrick as yb\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "\n",
    "df = pd.read_excel('docs/list_project_updated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure we have the columns and it imported \n",
    "print(df.columns)\n",
    "\n",
    "#The categorical variables needed to one hot encode\n",
    "cat_var = [key for key in dict(df.dtypes) if dict(df.dtypes)[key] in ['object']] \n",
    "\n",
    "#Do not want to hot encode these.  \n",
    "cat_var.remove('CHD_OTHSP')\n",
    "cat_var.remove('SPECOTH')\n",
    "\n",
    "#show the categorical\n",
    "print(cat_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This unnamed column gets added as an index from importing with pandas, not sure how to drop it in the \n",
    "#import so just dropping it here\n",
    "df.drop(df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "\n",
    "#Looking at the data specs\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode everything\n",
    "df_processed = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_var)\n",
    "\n",
    "#Text variables to drop from the first model\n",
    "text = [key for key in dict(df_processed.dtypes) if dict(df_processed.dtypes)[key] in ['object']] \n",
    "\n",
    "#These are the text variables now because we transformed the others\n",
    "print(text)\n",
    "\n",
    "#Storing all continuous variables\n",
    "con_var = [key for key in dict(df_processed.dtypes) if dict(df_processed.dtypes)[key] not in ['object']] \n",
    "\n",
    "#We don't want this in any of the models, it's useless information\n",
    "con_var.remove('PATIENT_ID')\n",
    "\n",
    "#Look at how many people are flagged as Heterotaxy to ensure it was the amount Tobias thought\n",
    "\n",
    "print(df_processed['HETEROTAXY'].value_counts())\n",
    "\n",
    "#Look at the data\n",
    "df_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model without text fields\n",
    "#Drop the text fields\n",
    "df_model1 = df_processed.drop(text,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1\n",
    "\n",
    "#Look at missing\n",
    "def missing(dff):\n",
    "    print (round((dff.isnull().sum() * 100/ len(dff)),2).sort_values(ascending=False))\n",
    "\n",
    "#This is an issue\n",
    "missing(df_model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute with the median, I just randomly chose this...could do whatever.\n",
    "df_imp = df_model1.fillna(df_model1.median())\n",
    "\n",
    "df_imp\n",
    "\n",
    "#Huge class imbalacnce\n",
    "sns.set(font_scale=1.5)\n",
    "countplt=sns.countplot(x='HETEROTAXY', data=df_imp, palette ='hls')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data with Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Everything but the predictor\n",
    "cols = [col for col in df_imp.columns if col not in ['HETEROTAXY']]\n",
    "\n",
    "#The data with all columns but target\n",
    "data = df_imp[cols]\n",
    "\n",
    "#The predictor\n",
    "target = df_imp['HETEROTAXY']\n",
    "\n",
    "#Split the data\n",
    "data_train, data_test, target_train, target_test = train_test_split(data,target, shuffle=False, test_size = 0.20)\n",
    "\n",
    "#Print dimensions\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create an object of the type GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = gnb.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "#print the accuracy score of the model\n",
    "print(\"Naive-Bayes accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "\n",
    "#NEED TO FIX!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object of type LinearSVC\n",
    "svc_model = LinearSVC(random_state=0)\n",
    "\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = svc_model.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "#print the accuracy score of the model\n",
    "print(\"LinearSVC accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "\n",
    "#KEEP GETTING CONVERGENCE ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create an object of type LinearSVC\n",
    "logit = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = logit.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "#print the accuracy score of the model\n",
    "print(\"Logistic Regression : \",accuracy_score(target_test, pred, normalize = True))\n",
    "\n",
    "#KEEP GETTING CONVERGENCE ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding first text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just drop SPECOTH as we are adding the first text field\n",
    "df_model2 = df_processed.drop('SPECOTH',axis=1)\n",
    "\n",
    "#Turn missing into blanks\n",
    "df_model2[\"CHD_OTHSP\"] = df_model2.CHD_OTHSP.fillna('')\n",
    "\n",
    "# #Remove punctuation\n",
    "df_model2['CHD_OTHSP'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "#This removes stop words, transforms to lowercase, tokenizes, and calculated TFIDF\n",
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(df_model2['CHD_OTHSP'])\n",
    "\n",
    "temp = pd.DataFrame(x.toarray(),columns=tfidf.get_feature_names())\n",
    "\n",
    "#Concat the results with the original dataframe\n",
    "df_model2_final = pd.concat([df_model2, temp], axis=1)\n",
    "\n",
    "#NOw that we transformed it, we don;t need it anymore\n",
    "df_model_2 = df_model2_final.drop(\"CHD_OTHSP\",axis=1)\n",
    "\n",
    "#Checking\n",
    "print(df_model_2.columns.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute with the median, I just randomly chose this...could do whatever.\n",
    "df_imp2 = df_model_2.fillna(df_model_2.median())\n",
    "\n",
    "#Everything but the predictor\n",
    "cols_2 = [col for col in df_imp2.columns if col not in ['HETEROTAXY']]\n",
    "\n",
    "#The data with all columns but target\n",
    "data_2 = df_imp2[cols_2]\n",
    "\n",
    "#The predictor\n",
    "target_2 = df_imp2['HETEROTAXY']\n",
    "\n",
    "#Split the data\n",
    "data_train_2, data_test_2, target_train_2, target_test_2 = train_test_split(data_2,target_2, test_size = 0.20)\n",
    "\n",
    "df_imp2.dtypes.value_counts()\n",
    "\n",
    "#Print dimensions\n",
    "print(data_train_2.shape)\n",
    "print(data_test_2.shape)\n",
    "print(target_train_2.shape)\n",
    "print(target_test_2.shape)\n",
    "\n",
    "# #train the algorithm on training data and predict using the testing data\n",
    "pred2 = logit.fit(data_train_2, target_train_2).predict(data_test_2)\n",
    "\n",
    "#print the accuracy score of the model\n",
    "print(\"Logistic Regression : \",accuracy_score(target_test_2, pred2, normalize = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
